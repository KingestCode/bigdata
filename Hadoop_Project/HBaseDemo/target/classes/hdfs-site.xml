<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>

    <property>
        <name>dfs.nameservices</name>
        <value>mycluster</value>
    </property>

    <!-- myucluster下的名称节点两个id -->
    <property>
        <name>dfs.ha.namenodes.mycluster</name>
        <value>nn1,nn2</value>
    </property>

    <!-- 配置每个nn的rpc地址。 -->
    <property>
        <name>dfs.namenode.rpc-address.mycluster.nn1</name>
        <value>cs1:8020</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.mycluster.nn2</name>
        <value>cs6:8020</value>
    </property>

    <!-- 配置webui端口 -->
    <property>
        <name>dfs.namenode.http-address.mycluster.nn1</name>
        <value>cs1:50070</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.mycluster.nn2</name>
        <value>cs6:50070</value>
    </property>

    <!-- 名称节点共享编辑目录. -->
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://cs2:8485;cs3:8485;cs4:8485/mycluster</value>
    </property>

    <!-- java类，client使用它判断哪个节点是激活态。 -->
    <property>
        <name>dfs.client.failover.proxy.provider.mycluster</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>

    <!-- 脚本列表或者java类，在容灾保护激活态的nn. -->
    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>
            sshfence
            shell(/bin/true)
        </value>
    </property>

    <!-- ssh免密登陆 -->
    <property>
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>/home/ap/.ssh/id_rsa</value>
    </property>

    <!-- 配置 sshfence 隔离机制超时时间 -->
    <property>
        <name>dfs.ha.fencing.ssh.connect-timeout</name>
        <value>30000</value>
    </property>

    <!-- 配置JN存放edit的本地路径。 -->
    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>/home/ap/hadoopdata/journal</value>
    </property>


    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/home/ap/hadoopdata/namenode</value>
        <description>为了保证元数据namenode的安全一般配置多个不同目录</description>
    </property>

    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/home/ap/hadoopdata/datanode</value>
        <description>datanode 的数据存储目录</description>
    </property>

    <property>
        <name>dfs.replication</name>
        <value>3</value>
        <description>HDFS 的数据块的副本存储个数</description>
    </property>

    <property>
        <name>dfs.secondary.http.address</name>
        <value>cs3:50090</value>
        <description>secondarynamenode 运行节点的信息，和 namenode 不同节点</description>
    </property>

    <property>
        <name>dfs.webhdfs.enabled</name>
        <value>true</value>
    </property>

    <!-- 启用zk自动容灾 -->
    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>

</configuration>